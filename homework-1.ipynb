{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bedad3e",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "Due Thursday 1/22\n",
    "\n",
    "The main objectives of this assignment are: to test the set up your Python environment, introduce the use of Jupyter style cells, and compare classical machine learning models against a basic neural network on a toy classification problem (iris dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b04a3",
   "metadata": {},
   "source": [
    "## 1. Setup \n",
    "Load the necessary Python packages and load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb996b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using seaborn for EDA and visualization\n",
    "iris_df = sns.load_dataset('iris')\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "# Access the features (DataFrame) and target (Series) for ML tasks\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52ad8e",
   "metadata": {},
   "source": [
    "## 2. Basic Exploratory Data Analysis\n",
    "\n",
    "* Understand the structure of the dataset. \n",
    "* Calculate basic statistic for each feature\n",
    "* Explore the correlation between features\n",
    "* Explore the distribution of samples by their norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb81b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structure of the DataFrame\n",
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics of the dataset\n",
    "print(iris_df.describe())\n",
    "# Count the number of instances for each species\n",
    "print(iris_df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation between features using a correlation Heatmap\n",
    "sns.heatmap(iris_df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0feb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the L2-norm of the feature vectors per species\n",
    "#\n",
    "# Calculate the L2 norm for the feature vectors (first 4 columns)\n",
    "iris_df['feature_norm_l2'] = np.linalg.norm(iris_df.iloc[:, 0:4], axis=1)\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=iris_df, x='feature_norm_l2', hue='species', fill=True, palette='viridis')\n",
    "plt.title('Distribution of Feature Vector L2Norms per Species')\n",
    "plt.xlabel('L2 Norm ($\\|x\\|_2$)')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56681bb",
   "metadata": {},
   "source": [
    "## 3 Machine Learning Modeling and Evaluation\n",
    "\n",
    "### Simple Train/Test Split (Holdout Validation Method)\n",
    "Split the dataset into 2 parts: training (70%) and testing (30%). Make sure to stratefy the split. \n",
    "\n",
    "### Training\n",
    "Train the following models using scikit-learn:\n",
    "\n",
    "* Perceptron (use `Perceptron()`)\n",
    "* Decision Tree (use `DecisionTreeClassifier()`)\n",
    "* K-Nearest Neighbors (use `KNeighborsClassifier(n_neighbors=3)`)\n",
    "* Support Vector Machine (use `SVC(kernel='linear')`)\n",
    "* Multi-Layer Perceptron (use `MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000)`)\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "For each model, you must output:\n",
    "- A Confusion Matrix (visualized using `ConfusionMatrixDisplay`).\n",
    "- A Classification Report showing:\n",
    "    - Accuracy\n",
    "    - Precision (Macro Average)\n",
    "    - Recall (Macro Average)\n",
    "    - F1-Score (Macro Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Code\n",
    "# \n",
    "# Create a test/train split for X and y \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the classifier by printing the confusion matrix\n",
    "def evaluate_classifier(y_true, y_pred, class_names):\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=class_names)\n",
    "\n",
    "# Function to calculate overall accuracy, precision, recall, F1-score\n",
    "def classification_metrics(y_true, y_pred, class_names):\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a perceptron classifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "percep = Perceptron()\n",
    "percep.fit(X_train, y_train)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "y_pred = percep.predict(X_test)\n",
    "evaluate_classifier(y_test, y_pred, iris.target_names)\n",
    "classification_metrics(y_test, y_pred, iris.target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ea0aa",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "* Which model performed the worst? Looking at the Confusion Matrix, which two species did it struggle to distinguish?\n",
    "* Why is the Perceptron limited in its ability to solve non-linearly separable problems?\n",
    "* The MLP is technically a \"Deep Learning\" model. Did it significantly outperform the SVM or KNN on this specific dataset? Why or why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4299c",
   "metadata": {},
   "source": [
    "## 4. K-Fold Cross-Validation\n",
    "Performance results obtained with the holdout validation method can be highly unreliable for small datasets. \n",
    "Instead, evaluate the models using Stratified 5-Fold Cross-Validation. This ensures that every data point is used for both training and testing across different iterations.\n",
    "\n",
    "* Use `cross_val_score` to calculate the accuracy for each of the 5 folds.\n",
    "* Report the mean accuracy and the standard deviation for each model.\n",
    "* Generate one confusion matrix for each model using `cross_val_predict` to see the aggregate errors across all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dd6efc",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "* Why is a 5-Fold Cross-Validation mean accuracy more \"trustworthy\" than a single 80/20 split accuracy for a small dataset like Iris?\n",
    "\n",
    "* If a model has a very high mean accuracy but a very large standard deviation across folds, what does that tell you about the model's reliability?\n",
    "\n",
    "* Looking at your aggregate Confusion Matrices, which species was most commonly misidentified as another? Did all models struggle with the same pair of species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f02627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275e30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nndl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
